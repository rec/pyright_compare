{
    "commits": {
        "before": {
            "committer_date": "2025-05-22 16:36:57",
            "commit_id": "a15550b7762",
            "message": "[Cutlass] Use env var for EVT flag (#154099)"
        },
        "after": {
            "committer_date": "2025-05-22 16:49:08",
            "commit_id": "7d3dab6b901",
            "message": "Revert \"[BE]: Type previously untyped decorators (#153726)\""
        }
    },
    "completenessScore": [0.370318, 0.368023],
    "filename": "full-run/pyright_compare.083092.a15550b7762-7d3dab6b901.json",
    "diff": {
        "absolute": {
            "exportedSymbolCounts": {"withKnownType": -37, "withUnknownType": 37},
            "otherSymbolCounts": {"withKnownType": -4, "withUnknownType": 4},
            "completenessScore": -0.0022947159513768134
        },
        "percent": {
            "exportedSymbolCounts": {
                "withKnownType": -0.6196616982080053,
                "withUnknownType": 0.39652770335441
            },
            "otherSymbolCounts": {
                "withKnownType": -0.2081165452653486,
                "withUnknownType": 0.2361275088547816
            },
            "completenessScore": -0.619661698208001
        },
        "symbols": {
            "common": {
                "torch.ao.nn.quantizable.modules.activation.MultiheadAttention.dequantize": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.nn.quantized.dynamic.modules.rnn.GRU.forward_packed": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"hx\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor | None\"",
                            "Type of parameter \"input\" is partially unknown\n\u00a0\u00a0Parameter type is \"PackedSequence\""
                        ]
                    }
                },
                "torch.ao.nn.quantized.dynamic.modules.rnn.GRU.forward_tensor": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"hx\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor | None\"",
                            "Type of parameter \"input\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor\""
                        ]
                    }
                },
                "torch.ao.nn.quantized.dynamic.modules.rnn.LSTM.forward_packed": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"input\" is partially unknown\n\u00a0\u00a0Parameter type is \"PackedSequence\""
                        ]
                    }
                },
                "torch.ao.nn.quantized.dynamic.modules.rnn.LSTM.forward_tensor": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"input\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor\""
                        ]
                    }
                },
                "torch.ao.nn.quantized.modules.conv._ConvNd.__getstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.nn.quantized.modules.conv._ConvNd.__setstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing",
                            "Type annotation for parameter \"state\" is missing"
                        ]
                    }
                },
                "torch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams.set_weight": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"weight\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor\""
                        ]
                    }
                },
                "torch.ao.nn.quantized.modules.linear.LinearPackedParams.set_weight_bias": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"bias\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor | None\"",
                            "Type of parameter \"weight\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor\""
                        ]
                    }
                },
                "torch.ao.nn.sparse.quantized.linear.LinearPackedParams.__getstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.nn.sparse.quantized.linear.LinearPackedParams.__setstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing",
                            "Type annotation for parameter \"state\" is missing"
                        ]
                    }
                },
                "torch.ao.nn.sparse.quantized.linear.LinearPackedParams.set_weight_bias": {
                    "diagnostics": {
                        "added": [
                            "Type of parameter \"bias\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor | None\"",
                            "Type of parameter \"weight\" is partially unknown\n\u00a0\u00a0Parameter type is \"Tensor\""
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FakeQuantize.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FakeQuantize.extra_repr": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FakeQuantizeBase.disable_fake_quant": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FakeQuantizeBase.disable_observer": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.extra_repr": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.FixedQParamsObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.HistogramObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.MinMaxObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.MinMaxObserver.extra_repr": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.MinMaxObserver.reset_min_max_vals": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.NoopObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.PerChannelMinMaxObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.PerChannelMinMaxObserver.reset_min_max_vals": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.PlaceholderObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.PlaceholderObserver.extra_repr": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.RecordingObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.RecordingObserver.get_tensor_value": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.ReuseInputObserver.calculate_qparams": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.ao.quantization.observer.UniformQuantizationObserverBase.reset_min_max_vals": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.distributed.nn.api.remote_module._RemoteModule.__getstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.distributed.nn.api.remote_module._RemoteModule.__setstate__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing",
                            "Type annotation for parameter \"state\" is missing"
                        ]
                    }
                },
                "torch.jit.export": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing",
                            "Type annotation for parameter \"fn\" is missing"
                        ]
                    }
                },
                "torch.jit.unused": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing",
                            "Type annotation for parameter \"fn\" is missing"
                        ]
                    }
                },
                "torch.nn.modules.container.ModuleDict.__getitem__": {
                    "diagnostics": {
                        "added": [
                            "Return type is partially unknown\n\u00a0\u00a0Return type is \"Module\""
                        ]
                    }
                },
                "torch.nn.modules.container.ModuleList.__dir__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.nn.modules.container.ModuleList.__repr__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.nn.modules.container.ParameterList.__dir__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                },
                "torch.nn.modules.container.Sequential.__dir__": {
                    "diagnostics": {
                        "added": [
                            "Return type annotation is missing"
                        ]
                    }
                }
            }
        }
    }
}
