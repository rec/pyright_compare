* `2025-05-22`: `-0.229%` [`Revert "[BE]: Type previously untyped decorators (#153726)"`](https://github.com/pytorch/pytorch/commit/7d3dab6b901)
* `2025-09-02`: `-0.187%` [`[ONNX] Refactor torchscript based exporter (#161323)`](https://github.com/pytorch/pytorch/commit/524b78d4f67)
* `2025-07-29`: `-0.074%` [`Revert "[Dynamo][Better Engineering] Add typing annotations to guard and source (#158397)"`](https://github.com/pytorch/pytorch/commit/d987a6f7f00)
* `2025-06-24`: `-0.043%` [`Clean up HF components (#155707)`](https://github.com/pytorch/pytorch/commit/5dd9652389e)
* `2025-06-04`: `-0.037%` [`Revert "[BE][Ez]: Fully type nn.utils.clip_grad (#154801)"`](https://github.com/pytorch/pytorch/commit/50de6ae2536)
* `2025-03-20`: `-0.036%` [`Revert "Supporting non-tensor-data write_size in planner write items. (#149434)"`](https://github.com/pytorch/pytorch/commit/90ef7a95618)
* `2025-09-07`: `-0.035%` [`Revert "Add return-max-scores to flex-attention (#161667)"`](https://github.com/pytorch/pytorch/commit/104f2680e03)
* `2025-03-01`: `-0.032%` [`Revert "Initial implementation of host memory stats (#147660)"`](https://github.com/pytorch/pytorch/commit/a983b2b11ad)
* `2025-02-24`: `-0.030%` [`[FX] Refactor immutable collections implementation (#144640)`](https://github.com/pytorch/pytorch/commit/a50af71fb65)
* `2025-04-17`: `-0.029%` [`add generalized pareto distribution (GPD) (#135968)`](https://github.com/pytorch/pytorch/commit/2ed2cb58051)
* `2025-06-28`: `-0.028%` [`[ONNX] Delete symbolic caffe2 (#157102)`](https://github.com/pytorch/pytorch/commit/5692cbb818f)
* `2025-03-11`: `-0.025%` [`[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)`](https://github.com/pytorch/pytorch/commit/ef6296e7f20)
* `2025-03-08`: `-0.025%` [`[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)`](https://github.com/pytorch/pytorch/commit/17dbeb11db7)
* `2025-03-09`: `-0.025%` [`[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)`](https://github.com/pytorch/pytorch/commit/2149f6c6845)
* `2025-04-01`: `-0.025%` [`[Reland] Launch kernel on current stream & remove `record_stream` entirely (#150398)`](https://github.com/pytorch/pytorch/commit/35c45a4a315)
* `2025-04-30`: `-0.025%` [`Clean up conda usage in benchmark scripts (#152552)`](https://github.com/pytorch/pytorch/commit/3f10091d3c0)
* `2025-06-20`: `-0.022%` [`Revert "Upgrade to DLPack 1.0. (#145000)"`](https://github.com/pytorch/pytorch/commit/b4442f42a93)
* `2025-06-26`: `-0.021%` [`refine fp32 precision api (#125888)`](https://github.com/pytorch/pytorch/commit/53e0b9c3936)
* `2025-05-10`: `-0.021%` [`refine fp32 precision api (#125888)`](https://github.com/pytorch/pytorch/commit/4c11b261586)
* `2025-08-08`: `-0.021%` [`Add unified memory APIs for torch.accelerator (#152932)`](https://github.com/pytorch/pytorch/commit/84f7e88aef0)
* `2025-08-06`: `-0.021%` [`Add unified memory APIs for torch.accelerator (#152932)`](https://github.com/pytorch/pytorch/commit/15f1173e5d7)
* `2025-07-17`: `-0.021%` [`Add unified memory APIs for torch.accelerator (#152932)`](https://github.com/pytorch/pytorch/commit/2ad5c25cfc6)
* `2025-06-24`: `-0.021%` [`Add unified memory APIs for torch.accelerator (#152932)`](https://github.com/pytorch/pytorch/commit/35e44067c4d)
* `2025-05-19`: `-0.019%` [`Revert "Improve torch.ops typing (#153558)"`](https://github.com/pytorch/pytorch/commit/d81217be2e4)
* `2025-04-13`: `-0.016%` [`Clean up duplicated code in lr_scheduler (#150984)`](https://github.com/pytorch/pytorch/commit/304633152c2)
* `2025-03-02`: `-0.016%` [`[fx] Move Node._prepend/Node._remove_from_list to C++ (#148261)`](https://github.com/pytorch/pytorch/commit/29c2de9ae16)
* `2025-03-10`: `-0.016%` [`[fx] Move Node._prepend/Node._remove_from_list to C++ (#148261)`](https://github.com/pytorch/pytorch/commit/5d4e7d58b42)
* `2025-05-28`: `-0.016%` [`Remove MemPoolContext  (#154042)`](https://github.com/pytorch/pytorch/commit/3b38989b5f8)
* `2025-05-31`: `-0.016%` [`Resubmit Remove MemPoolContext  (#154042) (#154746)`](https://github.com/pytorch/pytorch/commit/f01e628e3b3)
* `2025-02-14`: `-0.015%` [`[torch] Make amdsmi cdll hook private (#147207)`](https://github.com/pytorch/pytorch/commit/6f035d8462e)
* `2025-07-16`: `-0.015%` [`Add better typing to avaialbe kernel options for flex attention (#158383)`](https://github.com/pytorch/pytorch/commit/54848905398)
* `2025-01-17`: `-0.014%` [`[Pipelining] move scale_grads to base class, add docs (#144833)`](https://github.com/pytorch/pytorch/commit/5d54e7b812a)
* `2025-03-10`: `-0.011%` [`Revert "[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)"`](https://github.com/pytorch/pytorch/commit/ebd087e4b59)
* `2025-03-14`: `-0.011%` [`Revert "[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)"`](https://github.com/pytorch/pytorch/commit/f9b4856989c)
* `2025-09-02`: `-0.010%` [`Revert "Add __init__.pyi to torch/linalg (#160750)"`](https://github.com/pytorch/pytorch/commit/d6b74568e2c)
* `2025-07-12`: `-0.009%` [`[ONNX] Delete torch.onnx.dynamo_export (#158130)`](https://github.com/pytorch/pytorch/commit/2eff14c4455)
* `2025-06-15`: `-0.009%` [`[dynamo] Provide helper functions for guard filter hook (#155083)`](https://github.com/pytorch/pytorch/commit/54976bca103)
* `2025-03-19`: `-0.009%` [`[export] refactor DimHints for type errors (#149424)`](https://github.com/pytorch/pytorch/commit/96828a21559)
* `2025-08-14`: `-0.009%` [`[PP] Add DualPipeV schedule (#159591)`](https://github.com/pytorch/pytorch/commit/198b5fd2d47)
* `2025-09-04`: `-0.008%` [`kill allow_complex_guards_as_runtime_asserts (#161794)`](https://github.com/pytorch/pytorch/commit/3c45af079af)
* `2025-08-13`: `-0.008%` [`Revert "Add `label_smoothing` param in `nn.BCELoss` and `nn.BCEWithLogitsLoss` (#150282)"`](https://github.com/pytorch/pytorch/commit/641ee747815)
* `2025-08-28`: `-0.008%` [`kill allow_complex_guards_as_runtime_asserts (#160198)`](https://github.com/pytorch/pytorch/commit/196232bb935)
* `2025-08-28`: `-0.008%` [`kill allow_complex_guards_as_runtime_asserts (#160198)`](https://github.com/pytorch/pytorch/commit/69d91b94ba5)
* `2025-06-05`: `-0.008%` [`Add Intel GPU info collection to the collect env script (#137846)`](https://github.com/pytorch/pytorch/commit/e1180c7228b)
* `2025-04-01`: `-0.007%` [`infer dynamic shapes through additional inputs (#150144)`](https://github.com/pytorch/pytorch/commit/b70d105c779)
* `2025-07-26`: `-0.007%` [`[Inductor] Support native Inductor as backend for MTIA (#158526)`](https://github.com/pytorch/pytorch/commit/cd68559d045)
* `2025-07-29`: `-0.007%` [`[Re-land][Inductor] Support native Inductor as backend for MTIA (#159211)`](https://github.com/pytorch/pytorch/commit/c55e72bea14)
* `2025-08-13`: `-0.007%` [`[DCP][OSS] Rank local checkpointing in DCP without collectives (#147758)`](https://github.com/pytorch/pytorch/commit/6ee175195ac)
* `2025-03-21`: `-0.007%` [`pretty print graph signature (#149710)`](https://github.com/pytorch/pytorch/commit/fb07fe6f366)
* `2025-02-08`: `-0.006%` [`[ONNX] Adjust and add deprecation messages (#146639)`](https://github.com/pytorch/pytorch/commit/63c2909ae3e)
* `2025-02-12`: `-0.006%` [`[ONNX][reland2] Create deprecation warning on dynamo_export (#146923)`](https://github.com/pytorch/pytorch/commit/7f62616a585)
* `2025-04-15`: `-0.006%` [`Revert "Add inductor standalone_compile API (#150670)"`](https://github.com/pytorch/pytorch/commit/74f6bc28a72)
* `2025-04-14`: `-0.006%` [`Revert "Add inductor standalone_compile API (#150670)"`](https://github.com/pytorch/pytorch/commit/24b3ab92550)
* `2025-04-11`: `-0.006%` [`[dynamo] Allow guards to be dropped with custom filter functions. (#150936)`](https://github.com/pytorch/pytorch/commit/86370fd6580)
* `2025-05-08`: `-0.006%` [`Fix evaluate_expr to include suppress_guards_tls in cache key (#152661)`](https://github.com/pytorch/pytorch/commit/7cdf5048ea4)
* `2025-05-16`: `-0.006%` [`Revert "cleanup, refactor and add missing  self._dde_suppressed checks (#152657)"`](https://github.com/pytorch/pytorch/commit/1748fa529a9)
* `2025-05-26`: `-0.006%` [`Re-enable FakeTensor caching for SymInts (#152662)`](https://github.com/pytorch/pytorch/commit/7d11c61c26c)
* `2025-05-30`: `-0.006%` [`Re-enable FakeTensor caching for SymInts (#152662)`](https://github.com/pytorch/pytorch/commit/fc0135ca118)
* `2025-04-06`: `-0.006%` [`[typing] Add type hints to `__init__` methods in `torch.distributions`. (#144197)`](https://github.com/pytorch/pytorch/commit/6c38b9be730)
* `2025-07-09`: `-0.005%` [`Add Intel GPU info collection to the collect env script (#157351)`](https://github.com/pytorch/pytorch/commit/c515385b0ac)
* `2025-06-11`: `-0.005%` [`Add Intel GPU info collection to the collect env script (#137846)`](https://github.com/pytorch/pytorch/commit/5264f8cd8d0)
* `2025-06-06`: `-0.005%` [`Add Intel GPU info collection to the collect env script (#137846)`](https://github.com/pytorch/pytorch/commit/c6b4f98625b)
* `2025-09-07`: `-0.005%` [`[nativert] AOTI lowering and packaging as NativeRT delegate (#162285)`](https://github.com/pytorch/pytorch/commit/b919560c4a7)
* `2025-07-25`: `-0.005%` [`Revert "[BE] Remove __reduce_deploy__ (#158291)"`](https://github.com/pytorch/pytorch/commit/a9f6770edd8)
* `2025-07-21`: `-0.005%` [`Revert "[BE] Remove __reduce_deploy__ (#158291)"`](https://github.com/pytorch/pytorch/commit/920f26c7617)
* `2025-02-11`: `-0.005%` [`[MTIA] (4/n) Implement PyTorch APIs to query/reset device peak memory usage (#146751)`](https://github.com/pytorch/pytorch/commit/001ebbf734a)
* `2025-02-17`: `-0.005%` [`[Intel GPU] allow_tf32 for oneDNN backend - XPU part (#137570)`](https://github.com/pytorch/pytorch/commit/ae351d4d0ee)
* `2025-06-04`: `-0.005%` [`[ONNX] Create support for rotary embeddings (#154745)`](https://github.com/pytorch/pytorch/commit/3e57de1251b)
* `2025-06-18`: `-0.005%` [`Provide access to the cudaGraph_t underlying a CUDAGraph. (#155164)`](https://github.com/pytorch/pytorch/commit/9ed0060225a)
* `2025-03-31`: `-0.005%` [`[dynamic shapes] C++ bindings for guard_or_false/true (#150148)`](https://github.com/pytorch/pytorch/commit/284b7668980)
* `2025-04-07`: `-0.005%` [`Support having no metadata file for HuggingFaceStorageReader (#150701)`](https://github.com/pytorch/pytorch/commit/78fe079c97f)
* `2025-03-18`: `-0.005%` [`[ONNX] Expose verification utilities (#148603)`](https://github.com/pytorch/pytorch/commit/ebabd0efddd)
* `2025-03-27`: `-0.005%` [`Introduce guard_or_true, guard_or_false (#148430)`](https://github.com/pytorch/pytorch/commit/d5593ea31ce)
* `2025-03-27`: `-0.005%` [`Introduce guard_or_true, guard_or_false (#148430)`](https://github.com/pytorch/pytorch/commit/6cbcdee9445)
* `2025-01-21`: `-0.004%` [`Unconditionally exclude upper bound in all size oblivious tests (#144867)`](https://github.com/pytorch/pytorch/commit/323fb4dad0e)
* `2025-01-21`: `-0.004%` [`PEP585 update - torch/utils (#145201)`](https://github.com/pytorch/pytorch/commit/2f9d378f7bd)
* `2025-01-28`: `-0.004%` [`Revert "Add option to serialization config to reduce random reads from get_record_offset when loading with mmap=True (#143880)"`](https://github.com/pytorch/pytorch/commit/90106492928)
* `2025-02-13`: `-0.004%` [`Revert "Implement cuda graphs implementation of torch.cond and torch.while_loop (#140979)"`](https://github.com/pytorch/pytorch/commit/9a883007a2f)
* `2025-03-25`: `-0.004%` [`[ONNX] Set is_in_onnx_export for dynamo=True (#149678)`](https://github.com/pytorch/pytorch/commit/280e48739a4)
* `2025-03-27`: `-0.004%` [`Revert "Use source hashing to generate consistent symbolic ids (#149665)"`](https://github.com/pytorch/pytorch/commit/af7719a2fa0)
* `2025-03-28`: `-0.004%` [`[export] refactor _Dim into Dim (#149891)`](https://github.com/pytorch/pytorch/commit/103bf64a3c7)
* `2025-04-13`: `-0.004%` [`Propagate callable parameter types using ParamSpec (#142306) (#151014)`](https://github.com/pytorch/pytorch/commit/8494d5582a1)
* `2025-04-22`: `-0.004%` [`Revert "Do not generate long log messaged for suppressed data dependent errors. (#151023)"`](https://github.com/pytorch/pytorch/commit/bc6c0bc344e)
* `2025-05-23`: `-0.004%` [`change guard_or impl for better perf and simplicity (#153674)`](https://github.com/pytorch/pytorch/commit/9e089bb5b67)
* `2025-06-03`: `-0.004%` [`Combine sticky pgo key with job id (#154863)`](https://github.com/pytorch/pytorch/commit/ea5b9eca74e)
* `2025-06-25`: `-0.004%` [`Consolidate stack trace in Tracer (#156257)`](https://github.com/pytorch/pytorch/commit/204db27a0c4)
* `2025-07-02`: `-0.004%` [`Back out "Include c++ stack traces when we hit constraint violation (#155603)" (#157406)`](https://github.com/pytorch/pytorch/commit/156bc243f0e)
* `2025-07-15`: `-0.004%` [`[ONNX] Remove legacy Dort (#158258)`](https://github.com/pytorch/pytorch/commit/5606c516fd8)
* `2025-07-23`: `-0.004%` [`[BE] remove torch deploy - conditionals (#158288)`](https://github.com/pytorch/pytorch/commit/ab26d4fbeb5)
* `2025-07-17`: `-0.004%` [`[BE] remove torch deploy - conditionals (#158288)`](https://github.com/pytorch/pytorch/commit/1a4268b8113)
* `2025-07-18`: `-0.004%` [`Revert "Add torch compile force disable caches alias (#158072)"`](https://github.com/pytorch/pytorch/commit/9a7c2f1f64b)
* `2025-07-29`: `-0.004%` [`[BE] remove torch deploy - conditionals (#158288)`](https://github.com/pytorch/pytorch/commit/6162e650b0e)
* `2025-08-22`: `-0.004%` [`[ONNX] Remove enable_fake_mode and exporter_legacy (#161222)`](https://github.com/pytorch/pytorch/commit/419a2dbf5f6)
* `2025-08-25`: `-0.004%` [`[nccl symm mem] don't use arg for mempool, correctly use symmetric registration in hooks (#161238)`](https://github.com/pytorch/pytorch/commit/726dce3c944)
* `2025-08-28`: `-0.004%` [`Allow parallel start NUMA binding (#161576)`](https://github.com/pytorch/pytorch/commit/768a1017c55)
* `2025-08-26`: `-0.004%` [`Revert "[ROCm] SDPA fix mem fault when dropout is enabled (#154864)"`](https://github.com/pytorch/pytorch/commit/9f6e1b8730d)
* `2025-05-14`: `-0.003%` [`Fix support of MixtureSameFamily [bugfix]. (#151317)`](https://github.com/pytorch/pytorch/commit/a54bf43baad)
* `2025-07-30`: `-0.002%` [`Fix ep deepcopy when there is python builitin name (#159478)`](https://github.com/pytorch/pytorch/commit/de7376537f2)
* `2025-08-01`: `-0.002%` [`[PP] Support OVERLAP_F_B computation type (#158978)`](https://github.com/pytorch/pytorch/commit/5e8b95605f5)
* `2025-08-12`: `-0.002%` [`Add ownership token when needed on GradientEdge (#160098)`](https://github.com/pytorch/pytorch/commit/8e6a3138581)
* `2025-07-23`: `-0.002%` [`Add basic torch.hash_tensor op (#154149)`](https://github.com/pytorch/pytorch/commit/7f649ed4f83)
* `2025-07-22`: `-0.002%` [`Using torch.accelerator in comm_mode_features_example.py and visualize_sharding_example.py (#157317)`](https://github.com/pytorch/pytorch/commit/37ded2ac906)
* `2025-08-13`: `-0.002%` [`Add utility to get computed kernel in torch.library (#158393)`](https://github.com/pytorch/pytorch/commit/1196bb1c2e4)
* `2025-08-13`: `-0.002%` [`[C10D] Add check_rng_sync util (#160283)`](https://github.com/pytorch/pytorch/commit/6da11d9aafc)
* `2025-07-15`: `-0.002%` [`add eq function to NodeSource (#158170)`](https://github.com/pytorch/pytorch/commit/1c6057fd179)
* `2025-08-24`: `-0.002%` [`[muon] Introduce Muon optimizer to PyTorch (#160213)`](https://github.com/pytorch/pytorch/commit/74280d09132)
* `2025-07-15`: `-0.002%` [`make node source hashable (#158322)`](https://github.com/pytorch/pytorch/commit/011026205a9)
* `2025-08-15`: `-0.002%` [`Separate provenance tracking to different levels (#160383)`](https://github.com/pytorch/pytorch/commit/aa99e0958f7)
* `2025-08-27`: `-0.002%` [`[rfc] aot precompile with custom backend api (#161383)`](https://github.com/pytorch/pytorch/commit/c36d18d7e86)
* `2025-07-12`: `-0.002%` [`[DCP][HF] [ez]Change where sharded tensors are saved (#158069)`](https://github.com/pytorch/pytorch/commit/627ba411366)
* `2025-07-20`: `-0.002%` [`DCP safetensors test fix (#158685)`](https://github.com/pytorch/pytorch/commit/4b02bd76d3e)
* `2025-07-21`: `-0.002%` [`Grab bag of (mostly) typing improvements (#158075)`](https://github.com/pytorch/pytorch/commit/22920c9138f)
* `2025-09-10`: `-0.002%` [`[ONNX] Expose the testing module (#162495)`](https://github.com/pytorch/pytorch/commit/c66e58b7d0d)
* `2025-01-16`: `-0.002%` [`Fix loading older state_dict into AdamW after refactor (#144972)`](https://github.com/pytorch/pytorch/commit/3908be676c7)
* `2025-01-17`: `-0.002%` [`[dcp] Integrate stream extensions into DCP impl (#143359)`](https://github.com/pytorch/pytorch/commit/9c909bf3bb1)
* `2025-01-27`: `-0.002%` [`[Custom Ops] Add a new API to allow users to register an autocast for the custom op (#145588)`](https://github.com/pytorch/pytorch/commit/ec91b7720fc)
* `2025-01-28`: `-0.002%` [`Record inputs at time of tracing, constrain to them for triton fn (#145448)`](https://github.com/pytorch/pytorch/commit/a699034eeca)
* `2025-02-04`: `-0.002%` [`[export] Additionally save pytree namedtuple field names (#145956)`](https://github.com/pytorch/pytorch/commit/0c37c332da5)
* `2025-02-05`: `-0.002%` [`Add generate_stage_to_rank_mapping utility (#146193)`](https://github.com/pytorch/pytorch/commit/4ee7d0de86e)
* `2025-02-06`: `-0.002%` [`Add torch.func.debug_unwrap (#146528)`](https://github.com/pytorch/pytorch/commit/15b1ac3e86d)
* `2025-02-10`: `-0.002%` [`Exclude upsample_bilinear2d.vec from default core ATen decomposition table (#141791)`](https://github.com/pytorch/pytorch/commit/3d604b17d91)
* `2025-02-11`: `-0.002%` [`Implement serializable getattr support for tensor subclasses (#145772)`](https://github.com/pytorch/pytorch/commit/ebd992724f5)
* `2025-02-16`: `-0.002%` [`xpu: support sycl with torch.utils.cpp_extension APIs (#132945)`](https://github.com/pytorch/pytorch/commit/607379960bc)
* `2025-02-16`: `-0.002%` [`xpu: support sycl with torch.utils.cpp_extension APIs (#132945)`](https://github.com/pytorch/pytorch/commit/d27ecf85db3)
* `2025-02-19`: `-0.002%` [`Re-land exclude upsample_bilinear2d.vec and nearest2d.vec from default export decomposition table (#147153)`](https://github.com/pytorch/pytorch/commit/f63db6255fd)
* `2025-02-21`: `-0.002%` [`[fx] demote node prepend to self log from warning to debug (#147538)`](https://github.com/pytorch/pytorch/commit/ac88a6c00d1)
* `2025-02-26`: `-0.002%` [`[Resubmit] Record input strides at time of tracing, constrain to them for triton fn (#147861)`](https://github.com/pytorch/pytorch/commit/c839fa4dd2c)
* `2025-03-11`: `-0.002%` [`[MPS] Make `torch.mps.compile_shader` public (#148972)`](https://github.com/pytorch/pytorch/commit/c18858d6331)
* `2025-03-18`: `-0.002%` [`Avoid unnecessary clone in torch.cuda.set_rng_state (#149283)`](https://github.com/pytorch/pytorch/commit/d80a70b58ad)
* `2025-03-24`: `-0.002%` [`[export] Save unflattened gm (#149717)`](https://github.com/pytorch/pytorch/commit/1e159db57c6)
* `2025-03-27`: `-0.002%` [`[export] Save unflattened gm (#150030)`](https://github.com/pytorch/pytorch/commit/8d1cfb63b5f)
* `2025-06-20`: `-0.002%` [`[ONNX] Implement Attention-23 (#156431)`](https://github.com/pytorch/pytorch/commit/fbbab794ef6)
* `2025-06-21`: `-0.002%` [`[compile][hierarchical compilation] Release nested_compile_region API (#156449)`](https://github.com/pytorch/pytorch/commit/fab85fc5f99)
* `2025-06-24`: `-0.002%` [`Implement guard collectives (optimized version) (#156562)`](https://github.com/pytorch/pytorch/commit/17eb649d559)
* `2025-05-24`: `-0.002%` [`Introduce statically_known_false (#154291)`](https://github.com/pytorch/pytorch/commit/53ecb8159aa)
* `2025-05-27`: `-0.002%` [`Add getDeviceProperties api to torch mtia device (#153577)`](https://github.com/pytorch/pytorch/commit/c52a002a220)
* `2025-04-15`: `-0.002%` [`Warn user of existing lock file to avoid infinite waiting (#149382)`](https://github.com/pytorch/pytorch/commit/f98150fc8e6)
* `2025-05-14`: `-0.002%` [`[export] Make draft_export public (#153219)`](https://github.com/pytorch/pytorch/commit/d51bc273781)
* `2025-05-11`: `-0.002%` [`[Ez][BE]: Fix click ImportError in torch/csrc/jit (#153323)`](https://github.com/pytorch/pytorch/commit/0104ac0f6f3)
* `2025-04-01`: `-0.002%` [`[Quant][PT2E] add a lowering pass for x86 backend (#149708)`](https://github.com/pytorch/pytorch/commit/3b0cd9b542b)
* `2025-04-30`: `-0.002%` [`Configurable logging for cpp_extensions.py (#152260)`](https://github.com/pytorch/pytorch/commit/7a3cae4b200)
* `2025-04-17`: `-0.002%` [`[DDP] add one option to allow skipping all reduce unused parameters (#151503)`](https://github.com/pytorch/pytorch/commit/d8bafd23ab2)
* `2025-04-18`: `-0.002%` [`Support C++ statically_known_true (#151346)`](https://github.com/pytorch/pytorch/commit/eb1f85a2a00)
* `2025-04-24`: `-0.002%` [`[dynamic shapes] user-code friendly statically_known_true, has_static_value (#151601)`](https://github.com/pytorch/pytorch/commit/2ee8de54b17)
* `2025-04-07`: `-0.002%` [`[AO] Refactor convert and add QuantAffinePlaceholderObserver (#150644)`](https://github.com/pytorch/pytorch/commit/eba05e2d3ef)
* `2025-04-10`: `-0.002%` [`Expose is_available API for torch.backends.mkldnn (#147432)`](https://github.com/pytorch/pytorch/commit/4273e5d15cf)
* `2025-04-10`: `-0.002%` [`Remove guard_size_oblivious from vector_norm decomposition. (#148809)`](https://github.com/pytorch/pytorch/commit/5471e80fb4c)
* `2025-04-11`: `-0.002%` [`Add `__all__` for `torch.utils.dlpack` (#149026)`](https://github.com/pytorch/pytorch/commit/85549fe6de3)
* `2025-04-14`: `-0.002%` [`[dynamic shapes] add sym_and, sym_or (#150456)`](https://github.com/pytorch/pytorch/commit/6dddd6520da)
* `2025-01-22`: `-0.002%` [`Reverting the PR adding Kleidiai-based int4 kernels (#145392)`](https://github.com/pytorch/pytorch/commit/0940eb6d44f)
* `2025-04-01`: `-0.001%` [`[dtensor][tp] add a ParallelStyle PrepareModuleInputOutput (#150372)`](https://github.com/pytorch/pytorch/commit/d2ad9aa2f29)
* `2025-05-23`: `-0.001%` [`[export] Move PT2ArchiveWriter/Reader to torch/export (#153795)`](https://github.com/pytorch/pytorch/commit/7e80f23516a)
* `2025-05-23`: `-0.001%` [`[export] Move PT2ArchiveWriter/Reader to torch/export (#153795)`](https://github.com/pytorch/pytorch/commit/3b21d792259)
* `2025-02-28`: `-0.001%` [`Define `__all__` for `torch.utils.tensorboard` (#147550)`](https://github.com/pytorch/pytorch/commit/1ae7cc41ca3)
* `2025-01-17`: `+0.000%` [`Use torch with statement in torch distributed module (#144951)`](https://github.com/pytorch/pytorch/commit/176cde62404)
* `2025-01-20`: `+0.000%` [`PEP585 update - torch/_higher_order_ops torch/_subclasses torch/backends torch/compiler torch/cuda torch/masked torch/mtia torch/nested (#145202)`](https://github.com/pytorch/pytorch/commit/805c4b597a1)
* `2025-01-24`: `+0.000%` [`[WIP] Move XNNPACKQuantizer from PyTorch to ExecuTorch (#144940)`](https://github.com/pytorch/pytorch/commit/f08b9bc7e4e)
* `2025-01-24`: `+0.000%` [`[PGNCCL] Add an API to get the status/error code at the PG level (#144498)`](https://github.com/pytorch/pytorch/commit/c0861d092ce)
* `2025-01-26`: `+0.000%` [`pickler for GraphModule (#141659)`](https://github.com/pytorch/pytorch/commit/c6ad08357bf)
* `2025-01-27`: `+0.000%` [`Revert "pickler for GraphModule (#141659)"`](https://github.com/pytorch/pytorch/commit/2de53b3b659)
* `2025-01-28`: `+0.000%` [`[BE]: Update typing of OrderedSet ancestor (#145783)`](https://github.com/pytorch/pytorch/commit/8e46d0f5951)
* `2025-01-29`: `+0.000%` [`[c10d] Add NCCL memory allocator (#145675)`](https://github.com/pytorch/pytorch/commit/9fd6722fc90)
* `2025-01-29`: `+0.000%` [`Revert "[c10d] Add NCCL memory allocator (#145675)"`](https://github.com/pytorch/pytorch/commit/6371c25b91f)
* `2025-01-29`: `+0.000%` [`Add fake_impl for unique_consecutive (#145649)`](https://github.com/pytorch/pytorch/commit/2e5886dcc45)
* `2025-01-29`: `+0.000%` [`[c10d] Add NCCL memory allocator (#145675)`](https://github.com/pytorch/pytorch/commit/18a7a04c4ad)
* `2025-01-30`: `+0.000%` [`Revert "[c10d] Add NCCL memory allocator (#145675)"`](https://github.com/pytorch/pytorch/commit/5fa28bbe407)
* `2025-01-30`: `+0.000%` [`[c10d] Add NCCL memory allocator (#145675)`](https://github.com/pytorch/pytorch/commit/51ee9b154e1)
* `2025-01-31`: `+0.000%` [`pickler for GraphModule (#141659)`](https://github.com/pytorch/pytorch/commit/57d8278ab90)
* `2025-02-13`: `+0.000%` [`[BE]: Make OrderedSet reversible (#146904)`](https://github.com/pytorch/pytorch/commit/8d94eb1e3bf)
* `2025-02-15`: `+0.000%` [`[PT][FSDP] support custom all reduce hook across FSDP units (#147114)`](https://github.com/pytorch/pytorch/commit/933f921b366)
* `2025-02-17`: `+0.000%` [`Fix non-bitwise type annotations for Tensor operators (see #145838) (#146845)`](https://github.com/pytorch/pytorch/commit/59b7e52ad8f)
* `2025-02-18`: `+0.000%` [`Revert "Fix non-bitwise type annotations for Tensor operators (see #145838) (#146845)"`](https://github.com/pytorch/pytorch/commit/302f56a1f2d)
* `2025-02-20`: `+0.000%` [`type `fully_shard` so that the return value can be chained with typing enabled (#147489)`](https://github.com/pytorch/pytorch/commit/9da250aadae)
* `2025-03-02`: `+0.000%` [`[fx] Move Node._update_args_kwargs to C++ (#148260)`](https://github.com/pytorch/pytorch/commit/0135f57f4aa)
* `2025-03-03`: `+0.000%` [`Significantly speed up save_cache_artifacts (#148227)`](https://github.com/pytorch/pytorch/commit/57addfcd580)
* `2025-03-04`: `+0.000%` [`add supports_coalescing property in c10d::Backend  to determine whether backend supports coalescing (#135338)`](https://github.com/pytorch/pytorch/commit/16d07988fc8)
* `2025-03-04`: `+0.000%` [`Revert "[fx] Move Node._update_args_kwargs to C++ (#148260)"`](https://github.com/pytorch/pytorch/commit/17d003fe75c)
* `2025-03-05`: `+0.000%` [`[Profiler] Add profiler activity for HPU devices (#148182)`](https://github.com/pytorch/pytorch/commit/edc3ca577e1)
* `2025-03-05`: `+0.000%` [`[ONNX] Create VerificationInterpreter (#148396)`](https://github.com/pytorch/pytorch/commit/50e827b3dfb)
* `2025-03-08`: `+0.000%` [`c10d/ProcessGroup: cleanup abort and shutdown (#148798)`](https://github.com/pytorch/pytorch/commit/7ffadff2868)
* `2025-03-10`: `+0.000%` [`[fx] Move Node._update_args_kwargs to C++ (#148260)`](https://github.com/pytorch/pytorch/commit/bf752c36da0)
* `2025-03-11`: `+0.000%` [`Support basic TorchBind in aot_compile and aoti_compile_and_package (#148506)`](https://github.com/pytorch/pytorch/commit/cf19efd3d9e)
* `2025-03-13`: `+0.000%` [`[Partitioner] Remove unnecessary upstream nodes in dependency viewer (#146580)`](https://github.com/pytorch/pytorch/commit/4a12777ffed)
* `2025-03-16`: `+0.000%` [`Support subclass constructor capturing in export (#147014)`](https://github.com/pytorch/pytorch/commit/6b1b95ad2ac)
* `2025-03-18`: `+0.000%` [`[FSDP2] Add set_reshard_after_forward (#149103)`](https://github.com/pytorch/pytorch/commit/5b8cc4709ab)
* `2025-03-19`: `+0.000%` [`debug ival swap (#149206)`](https://github.com/pytorch/pytorch/commit/20874a1f46c)
* `2025-03-19`: `+0.000%` [`[c10d] Add a collective time estimator for NCCL comms (#149343)`](https://github.com/pytorch/pytorch/commit/8bf3f3fc43b)
* `2025-03-27`: `+0.000%` [`[invoke_subgraph] Fake tensor prop caching (#149087)`](https://github.com/pytorch/pytorch/commit/a7596b4b34f)
* `2025-03-27`: `+0.000%` [`[graph partition] support splitting on custom ops (#149782)`](https://github.com/pytorch/pytorch/commit/c830d750e6a)
* `2025-03-29`: `+0.000%` [`[ROCm] change preferred blas lib defaults (#150212)`](https://github.com/pytorch/pytorch/commit/7a470c93206)
* `2025-03-31`: `+0.000%` [`[export] min/max ranges for dim hints (#149590)`](https://github.com/pytorch/pytorch/commit/925fd4aa2e4)
* `2025-04-02`: `+0.000%` [`Add needs_exact_strides operator tag for Inductor to force exact strides (#148063)`](https://github.com/pytorch/pytorch/commit/c69c3c885e8)
* `2025-04-09`: `+0.000%` [`[hop] support base_hop._gen_schema (#149688)`](https://github.com/pytorch/pytorch/commit/c714d2fc0ee)
* `2025-04-09`: `+0.000%` [`ProcessGroupGloo: support lazy_init (#150801)`](https://github.com/pytorch/pytorch/commit/f237ee54bfb)
* `2025-04-10`: `+0.000%` [`Revert "ProcessGroupGloo: support lazy_init (#150801)"`](https://github.com/pytorch/pytorch/commit/73f3d6d9aaa)
* `2025-04-10`: `+0.000%` [`[ONNX] Add asdict method to VerificationInfo class (#151024)`](https://github.com/pytorch/pytorch/commit/f304483e95b)
* `2025-04-11`: `+0.000%` [`Reapply "ProcessGroupGloo: support lazy_init (#150801)" (#151031)`](https://github.com/pytorch/pytorch/commit/df4e5294a66)
* `2025-04-14`: `+0.000%` [`[Easy] Add `output_size` in forward method of ConvTranspose2d (#150609)`](https://github.com/pytorch/pytorch/commit/5a64476ed64)
* `2025-04-23`: `+0.000%` [`[MegaCache] Return None on no compilation (#151921)`](https://github.com/pytorch/pytorch/commit/f9bdfe90ae6)
* `2025-04-24`: `+0.000%` [`[dynamo] Add guard serialization for tensor matches. (#151318)`](https://github.com/pytorch/pytorch/commit/81c4369d813)
* `2025-04-24`: `+0.000%` [`Revert "[dynamo] Add guard serialization for tensor matches. (#151318)"`](https://github.com/pytorch/pytorch/commit/b1d055fd6a0)
* `2025-04-25`: `+0.000%` [`[dynamo] Add guard serialization for tensor matches. (#151318)`](https://github.com/pytorch/pytorch/commit/a34c28e0d25)
* `2025-05-02`: `+0.000%` [`Optimize `Sequential` methods description (#147304)`](https://github.com/pytorch/pytorch/commit/d457b4492d1)
* `2025-05-08`: `+0.000%` [`Add torch._C.Tag.needs_contiguous_strides (#152859)`](https://github.com/pytorch/pytorch/commit/94ca3a4666d)
* `2025-05-21`: `+0.000%` [`[MegaCache] Make MegaCache generic to allow external plugins registration (#152977)`](https://github.com/pytorch/pytorch/commit/bb7e30c1658)
* `2025-05-26`: `+0.000%` [`Add missing docstring for `sym_ite` (#154201)`](https://github.com/pytorch/pytorch/commit/f55f2f42a7b)
* `2025-05-26`: `+0.000%` [`Use property instead of ClassVar for `Uniform.arg_constraints` and `Wishart.arg_constraints` (#154361)`](https://github.com/pytorch/pytorch/commit/839c9c61565)
* `2025-05-27`: `+0.000%` [`[ez] Add docblock for resolve_unbacked_bindings (#154374)`](https://github.com/pytorch/pytorch/commit/70fbd5e08c8)
* `2025-05-27`: `+0.000%` [`Make torch importable if compiled without TensorPipe (#154382)`](https://github.com/pytorch/pytorch/commit/5075df6feec)
* `2025-05-27`: `+0.000%` [`[ez] add docblock for is_accessor_node (#154375)`](https://github.com/pytorch/pytorch/commit/4fd8a54a414)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for RuntimeAssert (#154401)`](https://github.com/pytorch/pytorch/commit/b82fb57b672)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for free_symbols (#154378)`](https://github.com/pytorch/pytorch/commit/dcdaef5206d)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for free_unbacked_symbols (#154379)`](https://github.com/pytorch/pytorch/commit/07405a6cffc)
* `2025-05-28`: `+0.000%` [`[ez] add docblock to is_symbol_binding_fx_node (#154380)`](https://github.com/pytorch/pytorch/commit/08c29deb5fe)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for find_symbol_binding_fx_nodes (#154381)`](https://github.com/pytorch/pytorch/commit/8e25ba6963d)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for guard_scalar (#154385)`](https://github.com/pytorch/pytorch/commit/35a473e3644)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for _ShapeGuardPrinter (#154402)`](https://github.com/pytorch/pytorch/commit/473a93eb589)
* `2025-05-28`: `+0.000%` [`[ez] add docblock for ShapeGuardPythonPrinter (#154403)`](https://github.com/pytorch/pytorch/commit/476e0a643a2)
* `2025-05-28`: `+0.000%` [`[ez] add docblock to cast_symbool_to_symint_guardless (#154400)`](https://github.com/pytorch/pytorch/commit/e7318b863db)
* `2025-05-28`: `+0.000%` [`Add docblock for TrackedFake (#154396)`](https://github.com/pytorch/pytorch/commit/ed348e70269)
* `2025-05-30`: `+0.000%` [`[dynamo] Trace into descriptor with `__set__` (#154176)`](https://github.com/pytorch/pytorch/commit/8002d22ce35)
* `2025-06-03`: `+0.000%` [`[c10d][gloo] Integrate vendor generic FR into gloo (#152614)`](https://github.com/pytorch/pytorch/commit/ff92b42fc33)
* `2025-06-04`: `+0.000%` [`[export] Refactor pt2 save/load (#152495)`](https://github.com/pytorch/pytorch/commit/d2bfd97d71c)
* `2025-06-07`: `+0.000%` [`[Profiler] Induce Inductor Import before Profiling (#155243)`](https://github.com/pytorch/pytorch/commit/abf4da0d242)
* `2025-06-10`: `+0.000%` [`Replace frame_traced_fn hook with get_traced_code() util (#155249)`](https://github.com/pytorch/pytorch/commit/c4b93e6579c)
* `2025-06-13`: `+0.000%` [`[precompile] Add CompilePackage to serialize dynamo states. (#155118)`](https://github.com/pytorch/pytorch/commit/b2fc9cfea16)
* `2025-06-13`: `+0.000%` [`[precompile] Implement PrecompileContext for recording precompile artifacts, integrate with CompilePackage (#154415)`](https://github.com/pytorch/pytorch/commit/3819584f12e)
* `2025-06-13`: `+0.000%` [`[BE][c10d/Store]add check in pyi (#155855) (#155865)`](https://github.com/pytorch/pytorch/commit/a5938ff4312)
* `2025-06-13`: `+0.000%` [`[Hierarchical-Compile] Track mutations for setitem (#155880)`](https://github.com/pytorch/pytorch/commit/4628f1b7a93)
* `2025-06-17`: `+0.000%` [`Enable NCCL zero-copy (user buffer registration) for FSDP2 (#150564)`](https://github.com/pytorch/pytorch/commit/0a0023d9840)
* `2025-06-18`: `+0.000%` [`[dynamo] add set_fullgraph decorator/context manager (#154289)`](https://github.com/pytorch/pytorch/commit/920f6e681ec)
* `2025-06-18`: `+0.000%` [`[dynamo] fix set_fullgraph for nested calls (#154782)`](https://github.com/pytorch/pytorch/commit/3c8c48f7934)
* `2025-06-18`: `+0.000%` [`[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)`](https://github.com/pytorch/pytorch/commit/a6a3a441442)
* `2025-06-18`: `+0.000%` [`Revert "[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)"`](https://github.com/pytorch/pytorch/commit/8f02161d101)
* `2025-06-18`: `+0.000%` [`Revert "[dynamo] fix set_fullgraph for nested calls (#154782)"`](https://github.com/pytorch/pytorch/commit/408d9884b07)
* `2025-06-18`: `+0.000%` [`Revert "[dynamo] add set_fullgraph decorator/context manager (#154289)"`](https://github.com/pytorch/pytorch/commit/c5d3e7a4ff4)
* `2025-06-18`: `+0.000%` [`Allow forcing FSDP2 to always use SUM reductions (#155915)`](https://github.com/pytorch/pytorch/commit/cbafba57941)
* `2025-06-19`: `+0.000%` [`Enable querying the build and runtime NCCL versions (#156305)`](https://github.com/pytorch/pytorch/commit/d4ad2804299)
* `2025-06-20`: `+0.000%` [`[dynamo] add set_fullgraph decorator/context manager (#154289)`](https://github.com/pytorch/pytorch/commit/2c372a05025)
* `2025-06-20`: `+0.000%` [`[dynamo] fix set_fullgraph for nested calls (#154782)`](https://github.com/pytorch/pytorch/commit/537b0877a87)
* `2025-06-20`: `+0.000%` [`[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)`](https://github.com/pytorch/pytorch/commit/0aed855b2bd)
* `2025-06-20`: `+0.000%` [`Revert "[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)"`](https://github.com/pytorch/pytorch/commit/754c04aa062)
* `2025-06-21`: `+0.000%` [`Add internal use only utility to allow externally visible side effects within HOPs (#155715)`](https://github.com/pytorch/pytorch/commit/554b5680405)
* `2025-06-22`: `+0.000%` [`Revert "[dynamo] fix set_fullgraph for nested calls (#154782)"`](https://github.com/pytorch/pytorch/commit/c10eeb5bad7)
* `2025-06-22`: `+0.000%` [`Revert "[dynamo] add set_fullgraph decorator/context manager (#154289)"`](https://github.com/pytorch/pytorch/commit/5e56db59d46)
* `2025-06-23`: `+0.000%` [`Implemented `Size.__radd__` (#152554)`](https://github.com/pytorch/pytorch/commit/2e9bd03f607)
* `2025-06-24`: `+0.000%` [`Fix non-bitwise type annotations for Tensor operators (see #145838) (#146845)`](https://github.com/pytorch/pytorch/commit/e2c9d8d6414)
* `2025-06-26`: `+0.000%` [`[dynamo] add set_fullgraph decorator/context manager (#154289)`](https://github.com/pytorch/pytorch/commit/7b7eafe7ba1)
* `2025-06-26`: `+0.000%` [`[dynamo] fix set_fullgraph for nested calls (#154782)`](https://github.com/pytorch/pytorch/commit/36666033aba)
* `2025-06-26`: `+0.000%` [`[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)`](https://github.com/pytorch/pytorch/commit/80d89974c17)
* `2025-06-28`: `+0.000%` [`[hop] support torch.func.functional_call in hop subgraph (#155886)`](https://github.com/pytorch/pytorch/commit/836bb1941b5)
* `2025-06-30`: `+0.000%` [`[precompile] Detect source code changes for save/load. (#156432)`](https://github.com/pytorch/pytorch/commit/f096820d0f8)
* `2025-07-01`: `+0.000%` [`[dynamo] Ensure global state guard is preserved across serialization. (#157285)`](https://github.com/pytorch/pytorch/commit/0f9c1b374fb)
* `2025-07-02`: `+0.000%` [`[PT] support custom all_gather and reduce_scatter comms (#155189)`](https://github.com/pytorch/pytorch/commit/0364db7cd14)
* `2025-07-02`: `+0.000%` [`[dynamo, nested graph breaks] remove recursive cell/freevar in instruction tx (#154078)`](https://github.com/pytorch/pytorch/commit/bdb78191662)
* `2025-07-02`: `+0.000%` [`[dynamo] Support BUILTIN_MATCH serialization. (#157016)`](https://github.com/pytorch/pytorch/commit/e20784f228a)
* `2025-07-07`: `+0.000%` [`[WIP] Automatically load and save dynamo entries via caching_precompile (#155913)`](https://github.com/pytorch/pytorch/commit/e466dab164d)
* `2025-07-07`: `+0.000%` [`Revert "[WIP] Automatically load and save dynamo entries via caching_precompile (#155913)"`](https://github.com/pytorch/pytorch/commit/ae1094b72b7)
* `2025-07-07`: `+0.000%` [`Automatically load and save dynamo entries via caching_precompile (#155913)`](https://github.com/pytorch/pytorch/commit/be56a8d7ac0)
* `2025-07-08`: `+0.000%` [`remove allow-untyped-defs from torch/_classes.py (#157231)`](https://github.com/pytorch/pytorch/commit/9d8cf24b3be)
* `2025-07-08`: `+0.000%` [`Simplify the base classes of `_PyFutureMeta` (#157757)`](https://github.com/pytorch/pytorch/commit/5dc75f72d4e)
* `2025-07-08`: `+0.000%` [`Work: block_current_stream API (#156883)`](https://github.com/pytorch/pytorch/commit/1b3d69b59f9)
* `2025-07-09`: `+0.000%` [`fix type hints for interpolation functions (#157202)`](https://github.com/pytorch/pytorch/commit/8d070187e34)
* `2025-07-10`: `+0.000%` [`Enable set SDPA backend by torch.nn.attention.sdpa_kernel on XPU (#156669)`](https://github.com/pytorch/pytorch/commit/ba0d0de5e65)
* `2025-07-10`: `+0.000%` [`Allow Custom Time Unit When Printing Profiler Table (#157913)`](https://github.com/pytorch/pytorch/commit/9bf41633d76)
* `2025-07-11`: `+0.000%` [`Add `torch.segment_reduce` docs (#154352)`](https://github.com/pytorch/pytorch/commit/b4fc42ca807)
* `2025-07-11`: `+0.000%` [`[c10d] ProcessGroupGloo: support per operation timeouts (#158128)`](https://github.com/pytorch/pytorch/commit/2a8795a981c)
* `2025-07-12`: `+0.000%` [`dist2: cleanup non-option methods on PG (missing, timeouts) (#158123)`](https://github.com/pytorch/pytorch/commit/0d77364ee3f)
* `2025-07-12`: `+0.000%` [`[dynamo] trace through torch.get_device_module (#157980)`](https://github.com/pytorch/pytorch/commit/6b84cb29f97)
* `2025-07-14`: `+0.000%` [`[c10d] Prototype of `group_split` for dist2 work (#157716)`](https://github.com/pytorch/pytorch/commit/6b2bef10afa)
* `2025-07-15`: `+0.000%` [`[hop][dynamo] track run-ahead sym variables in side effects (#158273)`](https://github.com/pytorch/pytorch/commit/651b4a68f2a)
* `2025-07-16`: `+0.000%` [`[hop] add supports_higher_order_operators flag to TorchDispatchMode (#158077)`](https://github.com/pytorch/pytorch/commit/82b1c482929)
* `2025-07-16`: `+0.000%` [`[cond] add _FlopCounterMode support for cond  (#158067)`](https://github.com/pytorch/pytorch/commit/da05b7fb94f)
* `2025-07-16`: `+0.000%` [`[c10d]Prototype of remote_group_merge (#158287)`](https://github.com/pytorch/pytorch/commit/f58a680d09e)
* `2025-07-16`: `+0.000%` [`[Dynamo][Better Engineering] Support typing in codegen.py (#158386)`](https://github.com/pytorch/pytorch/commit/5951fcd50ac)
* `2025-07-16`: `+0.000%` [`[PP] Add eval() API to schedule (#157795)`](https://github.com/pytorch/pytorch/commit/1d584761622)
* `2025-07-18`: `+0.000%` [`Make torch.distributed.breakpoint() set a long timeout (#158481)`](https://github.com/pytorch/pytorch/commit/89d842fec52)
* `2025-07-19`: `+0.000%` [`[BE] document Adadelta and Adagrad APIs properly (#158483)`](https://github.com/pytorch/pytorch/commit/f73594164a3)
* `2025-07-20`: `+0.000%` [`[DLPack] Add support for missing keyword-arguments. (#150218)`](https://github.com/pytorch/pytorch/commit/a10f15718d9)
* `2025-07-21`: `+0.000%` [`[Dynamo][BetterEngineering] Type side_effects.py (#158605)`](https://github.com/pytorch/pytorch/commit/ea5b06ed5bc)
* `2025-07-21`: `+0.000%` [`[AOTI][CPU] Consider bias=None case for fbgemm_linear_fp16_weight (#158535)`](https://github.com/pytorch/pytorch/commit/2c37acfd891)
* `2025-07-25`: `+0.000%` [`Device agnostic for DCP (#158337)`](https://github.com/pytorch/pytorch/commit/02ca965560e)
* `2025-07-25`: `+0.000%` [`Track descriptors for all inputs/outputs of AOTAutograd traced graph (#158624)`](https://github.com/pytorch/pytorch/commit/bf311141d6b)
* `2025-07-25`: `+0.000%` [`[BE] Make torch.nn.modules.* satisfy the docs coverage test (#158491)`](https://github.com/pytorch/pytorch/commit/9e8f27cc795)
* `2025-07-25`: `+0.000%` [`[BE] More torch.nn docs coverage test (except for torch.nn.parallel) (#158654)`](https://github.com/pytorch/pytorch/commit/1e79872f2e8)
* `2025-07-28`: `+0.000%` [`Partitioner: Fix to align partition node order with original graph (#157892)`](https://github.com/pytorch/pytorch/commit/2d1e92307d3)
* `2025-07-29`: `+0.000%` [`[c10d] Cleanup split_group logic using the newly built splitGroup (#158488)`](https://github.com/pytorch/pytorch/commit/67e68e07852)
* `2025-07-29`: `+0.000%` [`Revert "Partitioner: Fix to align partition node order with original graph (#157892)"`](https://github.com/pytorch/pytorch/commit/c0c24b61ff4)
* `2025-07-30`: `+0.000%` [`[ONNX] RMS Norm (#159377)`](https://github.com/pytorch/pytorch/commit/73ee3233807)
* `2025-08-04`: `+0.000%` [`[Dynamo][Better Engineering] Type coverage for `torch/_dynamo/utils.py` (#159580)`](https://github.com/pytorch/pytorch/commit/a7f3bdf5506)
* `2025-08-04`: `+0.000%` [`Feature: Implement support for `cudnn_batch_norm_out` kernel to replace the autogen approach. (#123020)`](https://github.com/pytorch/pytorch/commit/fd6655a0f5e)
* `2025-08-05`: `+0.000%` [`[Dynamo][Better Engineering] Type annotation for `torch/_dynamo/output_graph.py` (#159602)`](https://github.com/pytorch/pytorch/commit/b6c53383fe2)
* `2025-08-05`: `+0.000%` [`Allow controlling PG backend and options via init_device_mesh (#159371)`](https://github.com/pytorch/pytorch/commit/aeb5321b636)
* `2025-08-06`: `+0.000%` [`[Dynamo][Better Engineering] Typing `torch/_dynamo/guards.py` (#159315)`](https://github.com/pytorch/pytorch/commit/40c4d61f9ab)
* `2025-08-07`: `+0.000%` [`HF component update to not use fsspec components (#159405)`](https://github.com/pytorch/pytorch/commit/69cc606fda9)
* `2025-08-15`: `+0.000%` [`[PT2]: Add Static Dispatch Kernel for wrapped_fbgemm_linear_fp16_weight (#160451)`](https://github.com/pytorch/pytorch/commit/858fb80b9b2)
* `2025-08-16`: `+0.000%` [`Implement `list(UserDefinedObject)` via `force_unpack_var_sequence` (#159864)`](https://github.com/pytorch/pytorch/commit/f019da2979a)
* `2025-08-17`: `+0.000%` [`[easy] [Precompile] Refactor guards, improve typing (#160530)`](https://github.com/pytorch/pytorch/commit/63e1b58a134)
* `2025-08-18`: `+0.000%` [`Replace guard_serialization_mode with save_guards, remove load cases (#160531)`](https://github.com/pytorch/pytorch/commit/4014672b30f)
* `2025-08-19`: `+0.000%` [`Remove the uncessary empty file (#160728)`](https://github.com/pytorch/pytorch/commit/284b7190054)
* `2025-08-20`: `+0.000%` [`[BE][Dynamo] Type coverage for symbolic_convert (#160922)`](https://github.com/pytorch/pytorch/commit/54cc63b467f)
* `2025-08-20`: `+0.000%` [`[rfc] add hint_override kwarg to mark_dynamic (#161007)`](https://github.com/pytorch/pytorch/commit/0533ff2ccba)
* `2025-08-20`: `+0.000%` [`Revert "[rfc] add hint_override kwarg to mark_dynamic (#161007)"`](https://github.com/pytorch/pytorch/commit/90ea9ccefe3)
* `2025-08-20`: `+0.000%` [`[dynamo] Refactor convert_frame to remove usage of nonlocal tracer output return. [4/n] (#160899)`](https://github.com/pytorch/pytorch/commit/5255e65c01b)
* `2025-08-21`: `+0.000%` [`[rfc] add hint_override kwarg to mark_dynamic (#161007)`](https://github.com/pytorch/pytorch/commit/9a415701991)
* `2025-08-21`: `+0.000%` [`[dist] expose unsafe_get_ptr for dist.ProcessGroupNCCL.NCCLConfig (#161136)`](https://github.com/pytorch/pytorch/commit/18271148d32)
* `2025-08-21`: `+0.000%` [`Allow bypasses for Precompile when guards, etc. cannot be serialized (#160902)`](https://github.com/pytorch/pytorch/commit/96682103026)
* `2025-08-22`: `+0.000%` [`[fr] [xpu] Add FlightRecorder support for ProcessGroupXCCL (#158568)`](https://github.com/pytorch/pytorch/commit/9b4adc4db74)
* `2025-08-22`: `+0.000%` [`[dynamo] Support method calls on complex ConstantVariables (#161122)`](https://github.com/pytorch/pytorch/commit/4c36c8a9946)
* `2025-08-23`: `+0.000%` [`Support NUMA Binding for Callable Entrypoints, Take 2 (#161183)`](https://github.com/pytorch/pytorch/commit/33346b58148)
* `2025-08-25`: `+0.000%` [`[dynamo] Refactor convert_frame.compile_frame to be self contained function. [5/n] (#160900)`](https://github.com/pytorch/pytorch/commit/1113e7de30d)
* `2025-08-25`: `+0.000%` [`Revert "[dynamo] Refactor convert_frame.compile_frame to be self contained function. [5/n] (#160900)"`](https://github.com/pytorch/pytorch/commit/3e210f90c2c)
* `2025-08-25`: `+0.000%` [`[dynamo] Refactor convert_frame.compile_frame to be self contained function. [5/n] (#160900)`](https://github.com/pytorch/pytorch/commit/447d34b5f80)
* `2025-08-26`: `+0.000%` [`[dynamo, nested graph breaks] implement new resume frame stack/locals/cell layout convention (#157971)`](https://github.com/pytorch/pytorch/commit/2df9b437e37)
* `2025-08-26`: `+0.000%` [`[dynamo, nested graph breaks] add nested graph break tests (#144516)`](https://github.com/pytorch/pytorch/commit/9a756c2d710)
* `2025-08-26`: `+0.000%` [`[dynamo, nested graph breaks] support nested closures (#159817)`](https://github.com/pytorch/pytorch/commit/ef0ef6f93f7)
* `2025-08-26`: `+0.000%` [`Revert "[dynamo] Refactor convert_frame.compile_frame to be self contained function. [5/n] (#160900)"`](https://github.com/pytorch/pytorch/commit/e795450a35b)
* `2025-08-26`: `+0.000%` [`[dynamo] lift backed symint output of item() (#161198)`](https://github.com/pytorch/pytorch/commit/ba6ce66698f)
* `2025-08-26`: `+0.000%` [`type misc init and tools for dynamo (#161293)`](https://github.com/pytorch/pytorch/commit/f0e0a6897ee)
* `2025-08-26`: `+0.000%` [`[reland] [dynamo] Refactor convert_frame.compile_frame to be self contained function. [5/n] (#161514)`](https://github.com/pytorch/pytorch/commit/74124d1b467)
* `2025-08-26`: `+0.000%` [`Revert "[dynamo, nested graph breaks] support nested closures (#159817)"`](https://github.com/pytorch/pytorch/commit/a7aa480e55e)
* `2025-08-26`: `+0.000%` [`Revert "[dynamo, nested graph breaks] add nested graph break tests (#144516)"`](https://github.com/pytorch/pytorch/commit/6686974ddd7)
* `2025-08-27`: `+0.000%` [`[APS IR] Minfor fix - use GetAttrKey in get_keystr to match with flat args path in unflatten (#161453)`](https://github.com/pytorch/pytorch/commit/dbc903a94a4)
* `2025-08-27`: `+0.000%` [`[dynamo, nested graph breaks] add nested graph break tests (#144516)`](https://github.com/pytorch/pytorch/commit/8b78ba07b14)
* `2025-08-27`: `+0.000%` [`[dynamo][vllm] Support typing.get_type_hints (#161362)`](https://github.com/pytorch/pytorch/commit/3d406429b0a)
* `2025-08-27`: `+0.000%` [`[dynamo, nested graph breaks] support nested closures (#159817)`](https://github.com/pytorch/pytorch/commit/d0a242e5472)
* `2025-08-28`: `+0.000%` [`[PGO] skip allowlist logging for empty graphs (#161530)`](https://github.com/pytorch/pytorch/commit/97a548b640f)
* `2025-08-28`: `+0.000%` [`Add option for TorchDispatchMode to ignore torch.compile internals (#161648)`](https://github.com/pytorch/pytorch/commit/5edc3d814f4)
* `2025-09-03`: `+0.000%` [`[dynamo, nested graph breaks] support nested graph breaks that cause skipped frames (#160470)`](https://github.com/pytorch/pytorch/commit/d5643e8f3a6)
* `2025-09-03`: `+0.000%` [`[pt2e] Avoid getting model device once per node (#159901)`](https://github.com/pytorch/pytorch/commit/f4c33cd44ac)
* `2025-09-04`: `+0.000%` [`[dynamo] change error_on_graph_break/fullgraph semantics (#161747)`](https://github.com/pytorch/pytorch/commit/f36f2859537)
* `2025-09-04`: `+0.000%` [`fix incorrect interaction between DDPOptimizer and donated buffers (#160745)`](https://github.com/pytorch/pytorch/commit/0d71a9dd5b4)
* `2025-09-06`: `+0.000%` [`New export implementation with flat inp/out (#162167)`](https://github.com/pytorch/pytorch/commit/047603d35bd)
* `2025-09-08`: `+0.000%` [`shape guards (#161178)`](https://github.com/pytorch/pytorch/commit/711c8c821e8)
* `2025-09-09`: `+0.000%` [`testing infra and some fixes (#162183)`](https://github.com/pytorch/pytorch/commit/d8b6622bb6a)
* `2025-09-09`: `+0.000%` [`Revert "testing infra and some fixes (#162183)"`](https://github.com/pytorch/pytorch/commit/60d009267e5)
* `2025-05-23`: `+0.001%` [`Revert "[export] Move PT2ArchiveWriter/Reader to torch/export (#153795)"`](https://github.com/pytorch/pytorch/commit/4ff19ecf665)
* `2025-08-06`: `+0.002%` [`[Torch Package] Make get names of OrderedImporters support fallback to importers (#155743)`](https://github.com/pytorch/pytorch/commit/8ce81bcee1d)
* `2025-01-23`: `+0.002%` [`Revert "Reverting the PR adding Kleidiai-based int4 kernels (#145392)" (#145505)`](https://github.com/pytorch/pytorch/commit/41b38f755c4)
* `2025-02-20`: `+0.002%` [`[CPU Stream] Add noop for CPU stream record_event() and wait_event() (#145935)`](https://github.com/pytorch/pytorch/commit/6971b775104)
* `2025-03-05`: `+0.002%` [`Fix recent regression in evaluate_expr that effect cache lookups (#147836)`](https://github.com/pytorch/pytorch/commit/913356fb414)
* `2025-07-25`: `+0.002%` [`[ROCm] add flag torch.backends.miopen.immediate (#158951)`](https://github.com/pytorch/pytorch/commit/9b29166f57c)
* `2025-04-19`: `+0.002%` [`Don't specialize min/max (#151347)`](https://github.com/pytorch/pytorch/commit/adf5f38eae0)
* `2025-04-28`: `+0.002%` [`[BE] Migrate dtype_abbrs into one location (#152229)`](https://github.com/pytorch/pytorch/commit/13966d0bf55)
* `2025-04-29`: `+0.002%` [`Add rich support to torch.distributed.tensor.debug.visualize_sharding (#152027)`](https://github.com/pytorch/pytorch/commit/119cdcc926e)
* `2025-04-15`: `+0.002%` [`Remove ls from filesystem base (#151117)`](https://github.com/pytorch/pytorch/commit/c5de6ff079e)
* `2025-01-29`: `+0.002%` [`Revert "Record inputs at time of tracing, constrain to them for triton fn (#145448)"`](https://github.com/pytorch/pytorch/commit/0d6343347fb)
* `2025-02-11`: `+0.002%` [`Revert "Exclude upsample_bilinear2d.vec from default core ATen decomposition table (#141791)"`](https://github.com/pytorch/pytorch/commit/fe94ece375f)
* `2025-02-16`: `+0.002%` [`Revert "xpu: support sycl with torch.utils.cpp_extension APIs (#132945)"`](https://github.com/pytorch/pytorch/commit/dd5d0ea6bb0)
* `2025-03-19`: `+0.002%` [`Remove torch.export.export_for_inference (#149078)`](https://github.com/pytorch/pytorch/commit/fae79e91a0f)
* `2025-03-23`: `+0.002%` [`[ONNX] Clean up legacy dynamo export code (#149745)`](https://github.com/pytorch/pytorch/commit/2dccd70ef04)
* `2025-03-24`: `+0.002%` [`Revert "[export] Save unflattened gm (#149717)"`](https://github.com/pytorch/pytorch/commit/42e7bda53eb)
* `2025-07-03`: `+0.002%` [`[BE] Accelerator agnostic timer.py (#157131)`](https://github.com/pytorch/pytorch/commit/7081b8233a6)
* `2025-07-18`: `+0.002%` [`Revert "[DCP][HF] [ez]Change where sharded tensors are saved (#158069)"`](https://github.com/pytorch/pytorch/commit/e3351b3ddff)
* `2025-08-09`: `+0.002%` [`[BE] Remove more optim entries from docs coverage ignore list (#160194)`](https://github.com/pytorch/pytorch/commit/9b803cdbe29)
* `2025-07-31`: `+0.002%` [`Revert "Fix ep deepcopy when there is python builitin name (#159478)"`](https://github.com/pytorch/pytorch/commit/b1fb552974a)
* `2025-09-02`: `+0.004%` [`[BE][Easy] restore #157584 after #158288 (#158541)`](https://github.com/pytorch/pytorch/commit/13d66e2a66e)
* `2025-08-25`: `+0.004%` [`[CUDAGraph] Add getter for cuda graph exec (#161294)`](https://github.com/pytorch/pytorch/commit/cf94cadbeee)
* `2025-08-21`: `+0.004%` [`[DCP][HF] Add option to parallelize reads in HF Storage Reader (#160205)`](https://github.com/pytorch/pytorch/commit/46429be7232)
* `2025-08-23`: `+0.004%` [`Reland D80238201: [Torch.Export] Add flat arg paths in error message (#160919)`](https://github.com/pytorch/pytorch/commit/cd31be28ec5)
* `2025-08-21`: `+0.004%` [`[ROCm] SDPA fix mem fault when dropout is enabled (#154864)`](https://github.com/pytorch/pytorch/commit/3caddd4daa5)
* `2025-09-09`: `+0.004%` [`154849 Add support to handle IGUSR1 and SIGUSR2 in multiprocessing (#160690)`](https://github.com/pytorch/pytorch/commit/b498299953f)
* `2025-08-05`: `+0.004%` [`[export] Improve error messages (#159881)`](https://github.com/pytorch/pytorch/commit/fb35a9ea4ac)
* `2025-08-02`: `+0.004%` [`Add torch compile force disable caches alias (#158072)`](https://github.com/pytorch/pytorch/commit/a29ed5e1acc)
* `2025-07-25`: `+0.004%` [`Revert "[BE] remove torch deploy - conditionals (#158288)"`](https://github.com/pytorch/pytorch/commit/f8fafdc7a6d)
* `2025-07-24`: `+0.004%` [`Dont't GC as often when collecting cudagraphs (#158193)`](https://github.com/pytorch/pytorch/commit/e20736bf1d4)
* `2025-07-21`: `+0.004%` [`Revert "[BE] remove torch deploy - conditionals (#158288)"`](https://github.com/pytorch/pytorch/commit/ee5a434f8ce)
* `2025-07-17`: `+0.004%` [`Add torch compile force disable caches alias (#158072)`](https://github.com/pytorch/pytorch/commit/2ecf083b724)
* `2025-07-10`: `+0.004%` [`[HF][DCP] Upload local consolidated files to remote storage if needed (#157371)`](https://github.com/pytorch/pytorch/commit/3404c1f0cfe)
* `2025-07-15`: `+0.004%` [`Expose opt_einsum in torch.backends (#157740)`](https://github.com/pytorch/pytorch/commit/b7b1109f49f)
* `2025-07-07`: `+0.004%` [`correctly import torch.version (#157584)`](https://github.com/pytorch/pytorch/commit/ed6df0e3242)
* `2025-06-21`: `+0.004%` [`Enables NCCL symmetric memory kernels through mempool registration (#155134)`](https://github.com/pytorch/pytorch/commit/f70c80105eb)
* `2025-06-17`: `+0.004%` [`Add get_pipeline_order() for Gpipe and 1F1B (#155935)`](https://github.com/pytorch/pytorch/commit/38e1e5d54ce)
* `2025-06-12`: `+0.004%` [`Support XPU in memory tracker (#150703)`](https://github.com/pytorch/pytorch/commit/db01f1032ff)
* `2025-06-11`: `+0.004%` [`[reland] Add stack_trace on make_fx (#155486)`](https://github.com/pytorch/pytorch/commit/bc3972b80a7)
* `2025-06-11`: `+0.004%` [`Include c++ stack traces when we hit constraint violation (#155603)`](https://github.com/pytorch/pytorch/commit/5b9db4335e6)
* `2025-05-28`: `+0.004%` [`Add deprecation warning for `torch.ao.quantization` (#153892)`](https://github.com/pytorch/pytorch/commit/d23aa7e182e)
* `2025-05-27`: `+0.004%` [`add sticky cache pgo (#154418)`](https://github.com/pytorch/pytorch/commit/2560c1f3f00)
* `2025-05-27`: `+0.004%` [`[BE][CI][Easy] Run `lintrunner` on generated `.pyi` stub files (#150732)`](https://github.com/pytorch/pytorch/commit/7ae204c3b67)
* `2025-05-28`: `+0.004%` [`Support unbacked whitelist (#154295)`](https://github.com/pytorch/pytorch/commit/d865b784e4a)
* `2025-05-15`: `+0.004%` [`[BE] Add `__all__` to `torch/nn/functional.pyi` and `torch/return_types.pyi` (#150729)`](https://github.com/pytorch/pytorch/commit/a4c828199e0)
* `2025-05-14`: `+0.004%` [`[device_mesh] improve device selection logic (#150897)`](https://github.com/pytorch/pytorch/commit/4c5cf18ee05)
* `2025-04-28`: `+0.004%` [`Do not generate long log messages for suppressed data dependent errors. (#151023)`](https://github.com/pytorch/pytorch/commit/98bd2bd1abc)
* `2025-04-27`: `+0.004%` [`[Kineto] Enable OOM observer (#152160)`](https://github.com/pytorch/pytorch/commit/861945100ec)
* `2025-05-10`: `+0.004%` [`include user stacks with constraint violation error message (#152924)`](https://github.com/pytorch/pytorch/commit/70c8047c2d5)
* `2025-04-22`: `+0.004%` [`Do not generate long log messaged for suppressed data dependent errors. (#151023)`](https://github.com/pytorch/pytorch/commit/dfdf731579d)
* `2025-05-07`: `+0.004%` [`Fix bug visualizing 1D Tensor using rich (#152871)`](https://github.com/pytorch/pytorch/commit/93a0a7a0bf3)
* `2025-04-18`: `+0.004%` [`c10d/Store: add nonblocking mode to queue_pop (#151485)`](https://github.com/pytorch/pytorch/commit/98c892749bd)
* `2025-05-06`: `+0.004%` [`[invoke_subgraph] Run missing graph passes recursively (#152675)`](https://github.com/pytorch/pytorch/commit/97dfd8dd53f)
* `2025-01-17`: `+0.004%` [`Prevent legacy_load when weights_only=True (correctly) (#145020)`](https://github.com/pytorch/pytorch/commit/0eda02a94c7)
* `2025-01-22`: `+0.004%` [`Add a language option for symbolic shape guards (#143164)`](https://github.com/pytorch/pytorch/commit/fbaef0ac038)
* `2025-01-27`: `+0.004%` [`Add option to serialization config to reduce random reads from get_record_offset when loading with mmap=True (#143880)`](https://github.com/pytorch/pytorch/commit/db3685a35cd)
* `2025-01-28`: `+0.004%` [`Set -DPy_LIMITED_API flag for py_limited_api=True extensions (#145764)`](https://github.com/pytorch/pytorch/commit/515e55e6927)
* `2025-01-28`: `+0.004%` [`[inductor triton] Disable incorrect TF32 usage on CUDA capability < 8 (#145684)`](https://github.com/pytorch/pytorch/commit/5aa5a5763e5)
* `2025-01-31`: `+0.004%` [`Add option to serialization config to reduce random reads from get_record_offset when loading with mmap=True (#143880)`](https://github.com/pytorch/pytorch/commit/001e355a56a)
* `2025-02-01`: `+0.004%` [`execution trace export supports gzip format (#146179)`](https://github.com/pytorch/pytorch/commit/6e734bab93d)
* `2025-02-11`: `+0.004%` [`Implement cuda graphs implementation of torch.cond and torch.while_loop (#140979)`](https://github.com/pytorch/pytorch/commit/c7515da7b00)
* `2025-02-13`: `+0.004%` [`[DCP] Introduce modules metadata in the storage_meta (#146654)`](https://github.com/pytorch/pytorch/commit/7077d0ac8c2)
* `2025-02-14`: `+0.004%` [`[torch][amdsmi] Look for amdsmi in ROCM_HOME/ROCM_PATH before using rpath (#147117)`](https://github.com/pytorch/pytorch/commit/6419076db90)
* `2025-02-18`: `+0.004%` [`Add fqn_modifier at loading_state_dict and unit test (#146557)`](https://github.com/pytorch/pytorch/commit/a21a123fd57)
* `2025-02-20`: `+0.004%` [`add the `torch.float8_e8m0fnu` dtype to PyTorch (#147466)`](https://github.com/pytorch/pytorch/commit/382fbcc1e43)
* `2025-02-25`: `+0.004%` [`[DCP] Cache save plans in default planner (#147343)`](https://github.com/pytorch/pytorch/commit/6eb3d1e7627)
* `2025-02-28`: `+0.004%` [`Support whitelist of dynamic sources (#147979)`](https://github.com/pytorch/pytorch/commit/4708cfdbd93)
* `2025-03-06`: `+0.004%` [`Make record/storage alignment in torch.save configurable (#147788)`](https://github.com/pytorch/pytorch/commit/be0ceee1c37)
* `2025-03-11`: `+0.004%` [`[ez] include config as part of __all__ in torch.compiler (#148978)`](https://github.com/pytorch/pytorch/commit/2dcdb4ba782)
* `2025-03-27`: `+0.004%` [`Use source hashing to generate consistent symbolic ids (#149665)`](https://github.com/pytorch/pytorch/commit/1f92348dc6c)
* `2025-03-27`: `+0.004%` [`add `torch.float4_e2m1fn_x2` to PyTorch (#148791)`](https://github.com/pytorch/pytorch/commit/e33bc419588)
* `2025-03-28`: `+0.004%` [`Use source hashing to generate consistent symbolic ids (#149665)`](https://github.com/pytorch/pytorch/commit/f649ee73ce2)
* `2025-03-27`: `+0.005%` [`Revert "Introduce guard_or_true, guard_or_false (#148430)"`](https://github.com/pytorch/pytorch/commit/e080bac5336)
* `2025-05-02`: `+0.005%` [`consolidate guard_or_x and definitely_x (#152463)`](https://github.com/pytorch/pytorch/commit/376529c78b7)
* `2025-02-22`: `+0.005%` [`[PP] Remove extra code and docs BE (#147636)`](https://github.com/pytorch/pytorch/commit/5d26b7108f4)
* `2025-07-17`: `+0.005%` [`[BE] Remove __reduce_deploy__ (#158291)`](https://github.com/pytorch/pytorch/commit/0b9fb91f17e)
* `2025-07-30`: `+0.005%` [`[BE] Remove __reduce_deploy__ (#158291)`](https://github.com/pytorch/pytorch/commit/b57d1ef110b)
* `2025-07-23`: `+0.005%` [`[BE] Remove __reduce_deploy__ (#158291)`](https://github.com/pytorch/pytorch/commit/9c68c4d08f4)
* `2025-06-09`: `+0.005%` [`Revert "Add Intel GPU info collection to the collect env script (#137846)"`](https://github.com/pytorch/pytorch/commit/6fb62931593)
* `2025-06-11`: `+0.005%` [`Revert "Add Intel GPU info collection to the collect env script (#137846)"`](https://github.com/pytorch/pytorch/commit/45c5a232373)
* `2025-03-18`: `+0.006%` [`[ONNX] Create onnx_symbolic (#148905)`](https://github.com/pytorch/pytorch/commit/010963032c2)
* `2025-08-06`: `+0.006%` [`Partitioner: Fix to align partition node order with original graph (#157892)`](https://github.com/pytorch/pytorch/commit/2507ae63f29)
* `2025-09-07`: `+0.006%` [`[easy] [precompile] Convert CompileArtifacts to callable (#162169)`](https://github.com/pytorch/pytorch/commit/eb9073a6b71)
* `2025-07-08`: `+0.006%` [`remove allow-untyped-defs from torch/ao/nn/quantized/modules/rnn.py (#157234)`](https://github.com/pytorch/pytorch/commit/60b41de0ca0)
* `2025-05-30`: `+0.006%` [`remove allow-untyped-defs from torch/distributed/elastic/utils/logging.py (#154625)`](https://github.com/pytorch/pytorch/commit/d66a55def0c)
* `2025-05-30`: `+0.006%` [`remove allow-untyped-defs from torch/utils/data/datapipes/iter/filelister.py (#154624)`](https://github.com/pytorch/pytorch/commit/dc82e911e7f)
* `2025-05-30`: `+0.006%` [`Type hints for distributions/utils (#154712)`](https://github.com/pytorch/pytorch/commit/ba3f91af97c)
* `2025-06-03`: `+0.006%` [`[typing] Add missing type annotations to torch.nn.init module (#154504)`](https://github.com/pytorch/pytorch/commit/31405a69fb9)
* `2025-05-26`: `+0.006%` [`Revert "Re-enable FakeTensor caching for SymInts (#152662)"`](https://github.com/pytorch/pytorch/commit/3f64502c984)
* `2025-05-21`: `+0.006%` [`[BE][Ez]: Improve typing in torch/modules/container.py (#153728)`](https://github.com/pytorch/pytorch/commit/ffd49d538e8)
* `2025-05-19`: `+0.006%` [`cleanup, refactor and add missing  self._dde_suppressed checks (#152657)`](https://github.com/pytorch/pytorch/commit/0ec8fe46d7c)
* `2025-05-16`: `+0.006%` [`cleanup, refactor and add missing  self._dde_suppressed checks (#152657)`](https://github.com/pytorch/pytorch/commit/f7fb2f66e3b)
* `2025-05-15`: `+0.006%` [`[BE] Update `.pyi` stub template to use Generic TypeAlias (PEP 585) and Union Type (PEP 604) (#150728)`](https://github.com/pytorch/pytorch/commit/22b124335e0)
* `2025-05-06`: `+0.006%` [`Correct torch.xpu.is_bf16_supported return False if no XPU detected (#152317)`](https://github.com/pytorch/pytorch/commit/e32a16a9dad)
* `2025-04-15`: `+0.006%` [`Add inductor standalone_compile API (#150670)`](https://github.com/pytorch/pytorch/commit/3cf0e2d8ec8)
* `2025-04-14`: `+0.006%` [`Add inductor standalone_compile API (#150670)`](https://github.com/pytorch/pytorch/commit/c9aef508984)
* `2025-04-14`: `+0.006%` [`Add inductor standalone_compile API (#150670)`](https://github.com/pytorch/pytorch/commit/bbc5fe85045)
* `2025-02-10`: `+0.006%` [`Revert "[ONNX] Adjust and add deprecation messages (#146639)"`](https://github.com/pytorch/pytorch/commit/1557b7bf9a8)
* `2025-03-19`: `+0.006%` [`Cache the get_device_module result (#149207)`](https://github.com/pytorch/pytorch/commit/14dc6e732d0)
* `2025-03-05`: `+0.007%` [`Remove deprecate method and attirbute in `LRScheduler` (#147301)`](https://github.com/pytorch/pytorch/commit/fb1b7ec173a)
* `2025-07-26`: `+0.007%` [`Revert "[Inductor] Support native Inductor as backend for MTIA (#158526)"`](https://github.com/pytorch/pytorch/commit/fe0ff12dab7)
* `2025-02-06`: `+0.007%` [`[1/N][cp][example] flex attention in context parallel (forward pass) (#145896)`](https://github.com/pytorch/pytorch/commit/6220c64aeaf)
* `2025-06-06`: `+0.008%` [`Revert "Add Intel GPU info collection to the collect env script (#137846)"`](https://github.com/pytorch/pytorch/commit/0db3e0cf296)
* `2025-08-26`: `+0.008%` [`[1/n][export] Refactor PT2 Archive weight saving and loading (#160394)`](https://github.com/pytorch/pytorch/commit/089ad1d88bf)
* `2025-08-28`: `+0.008%` [`Revert "kill allow_complex_guards_as_runtime_asserts (#160198)"`](https://github.com/pytorch/pytorch/commit/a8270dd1248)
* `2025-08-28`: `+0.008%` [`Revert "kill allow_complex_guards_as_runtime_asserts (#160198)"`](https://github.com/pytorch/pytorch/commit/47742081c99)
* `2025-08-18`: `+0.008%` [`[PGO] add extra read/write keys (#160715)`](https://github.com/pytorch/pytorch/commit/075a2e69678)
* `2025-08-14`: `+0.008%` [`Add support for param mutation under inference mode (#159661)`](https://github.com/pytorch/pytorch/commit/194fcfcfbda)
* `2025-08-14`: `+0.008%` [`[MPS] Add API to query GPU core count (#160414)`](https://github.com/pytorch/pytorch/commit/a06ec54d400)
* `2025-08-12`: `+0.008%` [`Add `label_smoothing` param in `nn.BCELoss` and `nn.BCEWithLogitsLoss` (#150282)`](https://github.com/pytorch/pytorch/commit/f990490a238)
* `2025-07-17`: `+0.008%` [`[Dynamo][Better Engineering] Add type coverage to decorators (#158509)`](https://github.com/pytorch/pytorch/commit/b0e325c2c85)
* `2025-07-07`: `+0.008%` [`[oss] Add version to metadata (#155343)`](https://github.com/pytorch/pytorch/commit/5c79a55e7e5)
* `2025-06-11`: `+0.008%` [`set_grad_enabled add str and repr for prints (#155681)`](https://github.com/pytorch/pytorch/commit/18bf6addc47)
* `2025-06-01`: `+0.008%` [`[BE] Introduce torch.AcceleratorError (#152023)`](https://github.com/pytorch/pytorch/commit/0350c7e72c7)
* `2025-06-09`: `+0.008%` [`[1/n]adding torch.distributed.run option to provide destination for event logging (#154644) (#155268)`](https://github.com/pytorch/pytorch/commit/e15848669f8)
* `2025-05-17`: `+0.008%` [`Refactor `torch/utils/data/datapipes/gen_pyi.py` with `torchgen` (#150626)`](https://github.com/pytorch/pytorch/commit/9b2a45ac7d2)
* `2025-03-05`: `+0.008%` [`Add overload names to profiler trace (#143114)`](https://github.com/pytorch/pytorch/commit/b5873292c65)
* `2025-03-20`: `+0.008%` [`[export] Support python assertion with symints. (#149444)`](https://github.com/pytorch/pytorch/commit/f47aa081308)
* `2025-05-30`: `+0.008%` [`remove allow-untyped-defs from torch/ao/quantization/stubs.py (#154622)`](https://github.com/pytorch/pytorch/commit/0df96e3921d)
* `2025-03-04`: `+0.010%` [`[DCP] Introduce process based async checkpointing (#147039)`](https://github.com/pytorch/pytorch/commit/fdee60769ac)
* `2025-08-31`: `+0.010%` [`Add __init__.pyi to torch/linalg (#160750)`](https://github.com/pytorch/pytorch/commit/9a665ca3c47)
* `2025-08-12`: `+0.010%` [`Support NUMA Binding for Callable Entrypoints (#160163)`](https://github.com/pytorch/pytorch/commit/7e913949557)
* `2025-04-25`: `+0.011%` [`Add torch.accelerator.device_index as accelerator's device switch context (#148864)`](https://github.com/pytorch/pytorch/commit/33c75cae0a9)
* `2025-04-01`: `+0.011%` [`[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)`](https://github.com/pytorch/pytorch/commit/a10b765bf15)
* `2025-03-06`: `+0.011%` [`[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)`](https://github.com/pytorch/pytorch/commit/f08146b67ba)
* `2025-03-14`: `+0.011%` [`[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)`](https://github.com/pytorch/pytorch/commit/c95a6b416b4)
* `2025-09-08`: `+0.011%` [`Graph split event tracker (#159795)`](https://github.com/pytorch/pytorch/commit/fecd9686f54)
* `2025-02-12`: `+0.011%` [`[torch][amdsmi] Avoid ODR violation when loading amdsmi (#146324)`](https://github.com/pytorch/pytorch/commit/281249ba543)
* `2025-04-04`: `+0.012%` [`Add a param for save format in Storage Writer (#150025)`](https://github.com/pytorch/pytorch/commit/861d2cc02cc)
* `2025-07-12`: `+0.012%` [`remove allow-untyped-defs from torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py (#157848)`](https://github.com/pytorch/pytorch/commit/9508d73307b)
* `2025-06-13`: `+0.012%` [`remove allow-untyped-defs from adaround_fake_quantize.py (#155621)`](https://github.com/pytorch/pytorch/commit/60204406835)
* `2025-05-24`: `+0.012%` [`Update to using mypy 1.15 (#154054)`](https://github.com/pytorch/pytorch/commit/6503b4a96ed)
* `2025-01-23`: `+0.013%` [`Make torchelastic etcd rendezvous publicly importable (#145396)`](https://github.com/pytorch/pytorch/commit/6aaae9d78f0)
* `2025-02-14`: `+0.014%` [`Make torch.cuda.gds APIs public (#147120)`](https://github.com/pytorch/pytorch/commit/e8fbc86de02)
* `2025-05-30`: `+0.016%` [`Revert "Remove MemPoolContext  (#154042)"`](https://github.com/pytorch/pytorch/commit/d173ba5a756)
* `2025-04-03`: `+0.016%` [`Revert "[fx] Move Node._prepend/Node._remove_from_list to C++ (#148261)" (#150542)`](https://github.com/pytorch/pytorch/commit/d41c22b5781)
* `2025-03-04`: `+0.016%` [`Revert "[fx] Move Node._prepend/Node._remove_from_list to C++ (#148261)"`](https://github.com/pytorch/pytorch/commit/97b9e68bc65)
* `2025-06-22`: `+0.019%` [`Improve torch.ops typing (#154555)`](https://github.com/pytorch/pytorch/commit/54b8087f638)
* `2025-05-19`: `+0.019%` [`Improve torch.ops typing (#153558)`](https://github.com/pytorch/pytorch/commit/c5cba39d469)
* `2025-04-10`: `+0.019%` [`[export] Symint support (nonstrict, Dim.DYNAMIC) (#150198)`](https://github.com/pytorch/pytorch/commit/e6969c1bd8d)
* `2025-07-01`: `+0.019%` [`HF - consolidate shards of safetensors files to full tensors in finish step (#156705)`](https://github.com/pytorch/pytorch/commit/b60569ed946)
* `2025-03-21`: `+0.020%` [`[Distributed] Add `repr` methods for `ParallelStyle`s (#149478)`](https://github.com/pytorch/pytorch/commit/bf6621d08fe)
* `2025-06-25`: `+0.021%` [`Revert "Add unified memory APIs for torch.accelerator (#152932)"`](https://github.com/pytorch/pytorch/commit/6459a5c7a92)
* `2025-05-16`: `+0.021%` [`[export] Dynamo symint support (#152677)`](https://github.com/pytorch/pytorch/commit/3fe42d4d5d1)
* `2025-09-04`: `+0.021%` [`[DCP][HuggingFace] Add Support for dequantization of SafeTensors checkpoints (#160682)`](https://github.com/pytorch/pytorch/commit/12814701555)
* `2025-07-22`: `+0.021%` [`Revert "Add unified memory APIs for torch.accelerator (#152932)"`](https://github.com/pytorch/pytorch/commit/63413113332)
* `2025-08-07`: `+0.021%` [`Revert "Add unified memory APIs for torch.accelerator (#152932)"`](https://github.com/pytorch/pytorch/commit/74da2604c9d)
* `2025-05-11`: `+0.021%` [`Revert "refine fp32 precision api (#125888)"`](https://github.com/pytorch/pytorch/commit/fdc387ec7c9)
* `2025-06-30`: `+0.022%` [`Upgrade to DLPack 1.0. (#145000)`](https://github.com/pytorch/pytorch/commit/b54eac2a5ed)
* `2025-06-19`: `+0.022%` [`Upgrade to DLPack 1.0. (#145000)`](https://github.com/pytorch/pytorch/commit/6e185c53124)
* `2025-05-30`: `+0.022%` [`remove allow-untyped-defs from elastic_distributed_sampler.py (#154620)`](https://github.com/pytorch/pytorch/commit/20ee5f9044c)
* `2025-02-14`: `+0.023%` [`Make fx.node.map_arg() and .map_aggregate() generic (#146248)`](https://github.com/pytorch/pytorch/commit/272ead7b5e9)
* `2025-05-19`: `+0.025%` [`[BE]: Remove redundant copy (#153629)`](https://github.com/pytorch/pytorch/commit/f3daedb263d)
* `2025-03-09`: `+0.025%` [`Revert "[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)"`](https://github.com/pytorch/pytorch/commit/9cb25f0ea28)
* `2025-03-17`: `+0.025%` [`Revert "[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)"`](https://github.com/pytorch/pytorch/commit/afa1eda901b)
* `2025-03-10`: `+0.025%` [`Revert "[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)"`](https://github.com/pytorch/pytorch/commit/a95eb0c0a7d)
* `2025-07-01`: `+0.031%` [`remove allow-untyped-defs from torch/fx/experimental/migrate_gradual_types/util.py (#157236)`](https://github.com/pytorch/pytorch/commit/a767e50adca)
* `2025-03-05`: `+0.032%` [`Initial implementation of host memory stats (#147660)`](https://github.com/pytorch/pytorch/commit/c65ee728f06)
* `2025-02-28`: `+0.032%` [`Initial implementation of host memory stats (#147660)`](https://github.com/pytorch/pytorch/commit/945e359fc1a)
* `2025-05-30`: `+0.034%` [`[multigraph] use specializations in compile_and_call_fx_graph (#153449)`](https://github.com/pytorch/pytorch/commit/9c06dff1ce9)
* `2025-09-08`: `+0.035%` [`Add return-max-scores to flex-attention (#161667)`](https://github.com/pytorch/pytorch/commit/ac9ccd0dc2d)
* `2025-09-05`: `+0.035%` [`Add return-max-scores to flex-attention (#161667)`](https://github.com/pytorch/pytorch/commit/486b20b73cf)
* `2025-01-27`: `+0.036%` [`Use `typing.IO[bytes]` instead of `io.BytesIO` in annotations (#144994)`](https://github.com/pytorch/pytorch/commit/835e770bad6)
* `2025-03-21`: `+0.036%` [`Supporting non-tensor-data write_size in planner write items. (#149699)`](https://github.com/pytorch/pytorch/commit/1b08aaeafe9)
* `2025-03-20`: `+0.036%` [`Supporting non-tensor-data write_size in planner write items. (#149434)`](https://github.com/pytorch/pytorch/commit/1442230a267)
* `2025-07-09`: `+0.037%` [`[BE][Ez]: Fully type nn.utils.clip_grad (#154801)`](https://github.com/pytorch/pytorch/commit/fcc682be4bd)
* `2025-07-09`: `+0.037%` [`[BE][Ez]: Auto add return type annotations for methods in torch/nn/module (#157925)`](https://github.com/pytorch/pytorch/commit/163f0d8f2ab)
* `2025-05-31`: `+0.037%` [`[BE][Ez]: Fully type nn.utils.clip_grad (#154801)`](https://github.com/pytorch/pytorch/commit/9ce2732b685)
* `2025-01-20`: `+0.044%` [`PEP585 update - torch/fx (#145166)`](https://github.com/pytorch/pytorch/commit/0b2a3687b9f)
* `2025-09-10`: `+0.044%` [`[cpp_extension] Add abstract base class to OrderedDictWrapper, and clarify torch.nn.Module typing`](https://github.com/pytorch/pytorch/commit/11e97bc7bd4)
* `2025-06-13`: `+0.048%` [`Change _hfstorage to hfstorage (#155837)`](https://github.com/pytorch/pytorch/commit/bf798a2f016)
* `2025-07-09`: `+0.049%` [`[BE][Ez]: Autotype torch/profiler with ruff ANN (#157923)`](https://github.com/pytorch/pytorch/commit/a1dad2f2d2c)
* `2025-01-19`: `+0.050%` [`PEP585 update - torch/ao/quantization (#145140)`](https://github.com/pytorch/pytorch/commit/9e0437a04a2)
* `2025-05-12`: `+0.062%` [`[BE]: Improve decorator typing for Optimizer subclasses (#153374)`](https://github.com/pytorch/pytorch/commit/f05b38aa267)
* `2025-07-25`: `+0.064%` [`NUMA binding integration with elastic agent and torchrun (#149334)`](https://github.com/pytorch/pytorch/commit/7ef3c3357d8)
* `2025-07-30`: `+0.074%` [`[Dynamo][Better Engineering] Add typing annotations to guard and source (#158397) (#159491)`](https://github.com/pytorch/pytorch/commit/2b1ae29960e)
* `2025-07-24`: `+0.074%` [`[Dynamo][Better Engineering] Add typing annotations to guard and source (#158397)`](https://github.com/pytorch/pytorch/commit/abcb24f4de1)
* `2025-06-30`: `+0.074%` [`[remove untyped defs] batch 1 (#157011)`](https://github.com/pytorch/pytorch/commit/7709ff55123)
* `2025-05-17`: `+0.079%` [`[export] Move PT2 constants to torch::_export (#153206)`](https://github.com/pytorch/pytorch/commit/b4fb801b2d5)
* `2025-06-29`: `+0.093%` [`[DCP] OSS Zero Overhead Checkpointing Implementation (#156207)`](https://github.com/pytorch/pytorch/commit/2796f31b5e3)
* `2025-07-15`: `+0.111%` [`Fix types in graphs.py (#158192)`](https://github.com/pytorch/pytorch/commit/250ae2531c5)
* `2025-05-15`: `+0.124%` [`[torchgen] Refactor and simplify `gen_pyi.py` to use Generic TypeAlias (PEP 585) and Union Type (PEP 604) (#150727)`](https://github.com/pytorch/pytorch/commit/f7a5aa1d8d3)
* `2025-04-15`: `+0.168%` [`Optimize typing in `lr_scheduler.py` (#151219)`](https://github.com/pytorch/pytorch/commit/25803d3a22a)
* `2025-05-29`: `+0.229%` [`BE: Type previously untyped decorators (#154515)`](https://github.com/pytorch/pytorch/commit/946a4c2bdca)
* `2025-05-21`: `+0.229%` [`[BE]: Type previously untyped decorators (#153726)`](https://github.com/pytorch/pytorch/commit/b7d08defe9c)
